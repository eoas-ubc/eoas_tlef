{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Curve-Fitting\" data-toc-modified-id=\"Curve-Fitting-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Curve Fitting</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-linear-regression-for-fitting-non-linear-functions\" data-toc-modified-id=\"Using-linear-regression-for-fitting-non-linear-functions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Using linear regression for fitting non-linear functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-regression-for-fitting-an-exponential-function\" data-toc-modified-id=\"Linear-regression-for-fitting-an-exponential-function-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Linear regression for fitting an exponential function</a></span></li><li><span><a href=\"#Linear-regression-for-fitting-a-power-law-function\" data-toc-modified-id=\"Linear-regression-for-fitting-a-power-law-function-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Linear regression for fitting a power-law function</a></span></li></ul></li><li><span><a href=\"#Nonlinear-fitting\" data-toc-modified-id=\"Nonlinear-fitting-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Nonlinear fitting</a></span></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Exercises</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python\n",
    "\n",
    "single: curve fitting\n",
    "\n",
    "Curve Fitting\n",
    "=============\n",
    "\n",
    "One of the most important tasks in any experimental science is modeling\n",
    "data and determining how well some theoretical function describes\n",
    "experimental data. In the last chapter, we illustrated how this can be\n",
    "done when the theoretical function is a simple straight line in the\n",
    "context of learning about Python functions and methods. Here we show how\n",
    "this can be done for a arbitrary fitting functions, including linear,\n",
    "exponential, power law, and other nonlinear fitting functions.\n",
    "\n",
    "Using linear regression for fitting non-linear functions\n",
    "--------------------------------------------------------\n",
    "\n",
    "We can use our results for linear regression with $\\chi^2$ weighting\n",
    "that we developed in Chapter 7 to fit functions that are nonlinear in\n",
    "the fitting parameters, *provided* we can transform the fitting function\n",
    "into one that is linear in the fitting parameters and in the independent\n",
    "variable ($x$).\n",
    "\n",
    "single: curve fitting; linear; exponential function\n",
    "\n",
    "### Linear regression for fitting an exponential function\n",
    "\n",
    "To illustrate this approach, let's consider some experimental data taken\n",
    "from a radioactive source that was emitting beta particles (electrons).\n",
    "We notice that the number of electrons emitted per unit time is\n",
    "decreasing with time. Theory suggests that the number of electrons $N$\n",
    "emitted per unit time should decay exponentially according to the\n",
    "equation\n",
    "\n",
    "$$N(t) = N_0 e^{-t/\\tau} \\;.$$\n",
    "\n",
    "This equation is nonlinear in $t$ and in the fitting parameter $\\tau$\n",
    "and thus cannot be fit using the method of the previous chapter.\n",
    "Fortunately, this is a special case for which the fitting function can\n",
    "be transformed into a linear form. Doing so will allow us to use the\n",
    "fitting routine we developed for fitting linear functions.\n",
    "\n",
    "We begin our analysis by transforming our fitting function to a linear\n",
    "form. To this end we take the logarithm of Eq. `eq:decay`:\n",
    "\n",
    "$$\\ln N = \\ln N_{0} -\\frac{t}{\\tau} \\;.$$\n",
    "\n",
    "With this tranformation our fitting function is linear in the\n",
    "independent variable $t$. To make our method work, however, our fitting\n",
    "function must be linear in the *fitting parameters*, and our transformed\n",
    "function is still nonlinear in the fitting parameters $\\tau$ and $N_0$.\n",
    "Therefore, we define new fitting parameters as follows\n",
    "\n",
    "$$\\begin{aligned}\n",
    "a &= \\ln N_{0}\\\\\n",
    "b &= -1/\\tau\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now if we define a new dependent variable $y = \\ln N$, then our fitting\n",
    "function takes the form of a fitting function that is linear in the\n",
    "fitting parameters $a$ and $b$\n",
    "\n",
    "$$y = a + bx$$\n",
    "\n",
    "where the independent variable is $x=t$ and the dependent variable is\n",
    "$y=\\ln N$.\n",
    "\n",
    "We are almost ready to fit our transformed fitting function, with\n",
    "transformed fitting parameters $a$ and $b$, to our transformed\n",
    "independent and dependent data, $x$ and $y$. The last thing we have to\n",
    "do is to transform the estimates of the uncertainties $\\delta N$ in $N$\n",
    "to the uncertainties $\\delta y$ in $y$ $(= \\ln N)$. So how much does a\n",
    "given uncertainty in $N$ translate into an uncertainty in $y$? In most\n",
    "cases, the uncertainty in $y$ is much smaller than $y$, *i.e.*\n",
    "$\\delta y \\ll y$; similarly $\\delta N \\ll N$. In this limit we can use\n",
    "differentials to figure out the relationship between these\n",
    "uncertainties. Here is how it works for this example:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "y &= \\ln N\\\\\n",
    "\\delta y &= \\left|\\frac{\\partial y}{\\partial N}\\right|\\delta N\\\\\n",
    "\\delta y &= \\frac{\\delta N} {N} \\;.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Equation `eq:sigmaLnN` tells us how a small change $\\delta N$ in $N$\n",
    "produces a small change $\\delta y$ in $y$. Here we identify the\n",
    "differentials $dy$ and $dN$ with the uncertainties $\\delta y$ and\n",
    "$\\delta N$. Therefore, an uncertainty of $\\delta N$ in $N$ corresponds,\n",
    "or translates, to an uncertainty $\\delta y$ in $y$.\n",
    "\n",
    "Let's summarize what we have done so far. We started with the some data\n",
    "points $\\{t_i,N_i\\}$ and some addition data $\\{\\delta N_i\\}$ where each\n",
    "datum $\\delta N_i$ corresponds to the uncertainty in the experimentally\n",
    "measured $N_i$. We wish to fit these data to the fitting function\n",
    "\n",
    "$$N(t) = N_0 e^{-t/\\tau} \\;.$$\n",
    "\n",
    "We then take the natural logarithm of both sides and obtain the linear\n",
    "equation\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\ln N &= \\ln N_{0} -\\frac{t}{\\tau} \\\\\n",
    "y &= a + bx\n",
    "\\end{aligned}$$\n",
    "\n",
    "with the obvious correspondences\n",
    "\n",
    "$$\\begin{aligned}\n",
    "x &= t\\\\\n",
    "y &= \\ln N\\\\\n",
    "a &= \\ln N_{0}\\\\\n",
    "b &= -1/\\tau\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now we can use the linear regression routine with $\\chi^2$ weighting\n",
    "that we developed in the previous section to fit `eq:TransformedSemilog`\n",
    "to the transformed data $x_i (= t_i)$ and $y_i (= \\ln N_i)$. The inputs\n",
    "are the tranformed data ${x_i}, {y_i}, {\\delta y_i}$. The outputs are\n",
    "the fitting parameters $a$ and $b$, as well as the estimates of their\n",
    "uncertainties $\\delta a$ and $\\delta b$ along with the value of\n",
    "$\\chi^2$. You can obtain the values of the original fitting parameters\n",
    "$N_0$ and $\\tau$ by taking the differentials of the last two equations\n",
    "in Eq. `eq:eqlist`:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\delta a &= \\left|\\frac{\\partial a}{\\partial N_0}\\right|\\delta N_0 \n",
    "          = \\frac{\\delta N_{0}}{N_{0}}\\\\\n",
    "\\delta b &= \\left|\\frac{\\partial b}{\\partial \\tau}\\right|\\delta \\tau\n",
    "          = \\frac{\\delta \\tau}{\\tau^2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "The Python routine below shows how to implement all of this for a set of\n",
    "experimental data that is read in from a data file.\n",
    "\n",
    "Figure `8.1 <fig:betaDecay>` shows the output of the fit to simulated\n",
    "beta decay data obtained using the program below. Note that the error\n",
    "bars are large when the number of counts $N$ are small. This is\n",
    "consistent with what is known as *shot noise* (noise that arises from\n",
    "counting discrete events), which obeys *Poisson* statistics. You will\n",
    "study sources of noise, including shot noise, later in your lab courses.\n",
    "The program also prints out the fitting parameters of the transformed\n",
    "data as well as the fitting parameters for the exponential fitting\n",
    "function.\n",
    "\n",
    "<figure>\n",
    "<img src=\"attachment:betaDecay.png\" class=\"align-center\" alt=\"\" /><figcaption>Semi-log plot of beta decay measurements from Phosphorus-32.</figcaption>\n",
    "</figure>\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def LineFitWt(x, y, sig):\n",
    "    \"\"\" \n",
    "    Fit to straight line.\n",
    "    Inputs: x and y arrays and uncertainty array (unc) for y data.\n",
    "    Ouputs: slope and y-intercept of best fit to data.\n",
    "    \"\"\"\n",
    "    sig2 = sig**2\n",
    "    norm = (1./sig2).sum()\n",
    "    xhat = (x/sig2).sum() / norm\n",
    "    yhat = (y/sig2).sum() / norm\n",
    "    slope = ((x-xhat)*y/sig2).sum()/((x-xhat)*x/sig2).sum()\n",
    "    yint = yhat - slope*xhat\n",
    "    sig2_slope = 1./((x-xhat)*x/sig2).sum()\n",
    "    sig2_yint = sig2_slope * (x*x/sig2).sum() / norm\n",
    "    return slope, yint, np.sqrt(sig2_slope), np.sqrt(sig2_yint)\n",
    "\n",
    "def redchisq(x, y, dy, slope, yint):\n",
    "    chisq = (((y-yint-slope*x)/dy)**2).sum()\n",
    "    return chisq/float(x.size-2)\n",
    "\n",
    "# Read data from data file\n",
    "t, N, dN = np.loadtxt(\"betaDecay.txt\", skiprows=2, unpack=True)\n",
    "\n",
    "########## Code to tranform & fit data starts here ##########\n",
    "\n",
    "# Transform data and parameters to linear form: Y = A + B*X\n",
    "X = t         # transform t data for fitting (trivial)\n",
    "Y = np.log(N) # transform N data for fitting\n",
    "dY = dN/N     # transform uncertainties for fitting\n",
    "\n",
    "# Fit transformed data X, Y, dY to obtain fitting parameters A & B\n",
    "# Also returns uncertainties in A and B\n",
    "B, A, dB, dA = LineFitWt(X, Y, dY)\n",
    "# Return reduced chi-squared\n",
    "redchisqr = redchisq(X, Y, dY, B, A)\n",
    "\n",
    "# Determine fitting parameters for original exponential function\n",
    "# N = N0 exp(-t/tau) ...\n",
    "N0 = np.exp(A)\n",
    "tau = -1.0/B\n",
    "# ... and their uncertainties\n",
    "dN0 = N0 * dA\n",
    "dtau = tau**2 * dB\n",
    "\n",
    "####### Code to plot transformed data and fit starts here #######\n",
    "\n",
    "# Create line corresponding to fit using fitting parameters\n",
    "# Only two points are needed to specify a straight line\n",
    "Xext = 0.05*(X.max()-X.min())\n",
    "Xfit = np.array([X.min()-Xext, X.max()+Xext])\n",
    "Yfit = A + B*Xfit\n",
    "\n",
    "plt.errorbar(X, Y, dY, fmt=\"bo\")\n",
    "plt.plot(Xfit, Yfit, \"r-\", zorder=-1)\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(1.5, 7)\n",
    "plt.title(\"$\\mathrm{Fit\\\\ to:}\\\\ \\ln N = -t/\\\\tau + \\ln N_0$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"ln(N)\")\n",
    "\n",
    "plt.text(50, 6.6, \"A = ln N0 = {0:0.2f} $\\pm$ {1:0.2f}\"\n",
    "         .format(A, dA))\n",
    "plt.text(50, 6.3, \"B = -1/tau = {0:0.4f} $\\pm$ {1:0.4f}\"\n",
    "         .format(-B, dB))\n",
    "plt.text(50, 6.0, \"$\\chi_r^2$ = {0:0.3f}\"\n",
    "         .format(redchisqr))\n",
    "\n",
    "plt.text(50, 5.7, \"N0 = {0:0.0f} $\\pm$ {1:0.0f}\"\n",
    "         .format(N0, dN0))\n",
    "plt.text(50, 5.4, \"tau = {0:0.1f} $\\pm$ {1:0.1f} days\"\n",
    "         .format(tau, dtau))\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "single: curve fitting; linear; power law function\n",
    "\n",
    "single: curve fitting; linear; power-law function\n",
    "\n",
    "### Linear regression for fitting a power-law function\n",
    "\n",
    "You can use a similar approach to the one outlined above to fit\n",
    "experimental data to a power law fitting function of the form\n",
    "\n",
    "$$P(s) = P_0 s^\\alpha \\;.$$\n",
    "\n",
    "We follow the same approach we used for the exponential fitting function\n",
    "and first take the logarithm of both sides of `eq:pwrlaw`\n",
    "\n",
    "$$\\ln P = \\ln P_0 + \\alpha \\ln s \\;.$$\n",
    "\n",
    "We recast this in the form of a linear equation $y = a + bx$ with the\n",
    "following identifications:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "x &= \\ln s\\\\\n",
    "y &= \\ln P\\\\\n",
    "a &= \\ln P_{0}\\\\\n",
    "b &= \\alpha\n",
    "\\end{aligned}$$\n",
    "\n",
    "Following a procedure similar to that used to fit using an exponential\n",
    "fitting function, you can use the tranformations given by\n",
    "`eq:eqPwrTrans` as the basis for a program to fit a power-law fitting\n",
    "function such as `eq:logpwrlaw` to experimental data.\n",
    "\n",
    "single: curve fitting; nonlinear\n",
    "\n",
    "Nonlinear fitting\n",
    "-----------------\n",
    "\n",
    "The method introduced in the previous section for fitting nonlinear\n",
    "fitting functions can be used only if the fitting function can be\n",
    "transformed into a fitting function that is linear in the fitting\n",
    "parameters $a$, $b$, $c$... When we have a nonlinear fitting function\n",
    "that cannot be transformed into a linear form, we need another approach.\n",
    "\n",
    "The problem of finding values of the fitting parameters that minimize\n",
    "$\\chi^2$ is a nonlinear optimization problem to which there is quite\n",
    "generally no analytical solution (in contrast to the linear optimization\n",
    "problem). We can gain some insight into this nonlinear optimization\n",
    "problem, namely the fitting of a nonlinear fitting function to a data\n",
    "set, by considering a fitting function with only two fitting parameters.\n",
    "That is, we are trying to fit some data set $\\{x_{i},y_{i}\\}$, with\n",
    "uncertainties in $\\{y_{i}\\}$ of $\\{\\sigma_{i}\\}$, to a fitting function\n",
    "is $f(x;a,b)$ where $a$ and $b$ are the two fitting parameters. To do\n",
    "so, we look for the minimum in\n",
    "\n",
    "$$\\chi^2(a,b) = \\sum_{i} \\left(\\frac{y_{i} - f(x_{i})}{\\sigma_{i}}\\right)^2 \\;.$$\n",
    "\n",
    "Note that once the data set, uncertainties, and fitting function are\n",
    "specified, $\\chi^2(a,b)$ is simply a function of $a$ and $b$. We can\n",
    "picture the function $\\chi^2(a,b)$ as a of landscape with peaks and\n",
    "valleys: as we vary $a$ and $b$, $\\chi^2(a,b)$ rises and falls. The\n",
    "basic idea of all nonlinear fitting routines is to start with some\n",
    "initial guesses for the fitting parameters, here $a$ and $b$, and by\n",
    "scanning the $\\chi^2(a,b)$ landscape, find values of $a$ and $b$ that\n",
    "minimize $\\chi^2(a,b)$.\n",
    "\n",
    "There are a number of different methods for trying to find the minimum\n",
    "in $\\chi^2$ for nonlinear fitting problems. Nevertheless, the method\n",
    "that is most widely used goes by the name of the *Levenberg-Marquardt*\n",
    "method. Actually the Levenberg-Marquardt method is a combination of two\n",
    "other methods, the *steepest descent* (or gradient) method and\n",
    "*parabolic extrapolation*. Roughly speaking, when the values of $a$ and\n",
    "$b$ are not too near their optimal values, the gradient descent method\n",
    "determines in which direction in $(a,b)$-space the function\n",
    "$\\chi^2(a,b)$ decreases most quickly---the direction of steepest\n",
    "descent---and then changes $a$ and $b$ accordingly to move in that\n",
    "direction. This method is very efficient unless $a$ and $b$ are very\n",
    "near their optimal values. Near the optimal values of $a$ and $b$,\n",
    "parabolic extrapolation is more efficient. Therefore, as $a$ and $b$\n",
    "approach their optimal values, the Levenberg-Marquardt method gradually\n",
    "changes to the parabolic extrapolation method, which approximates\n",
    "$\\chi^2(a,b)$ by a Taylor series second order in $a$ and $b$ and then\n",
    "computes directly the analytical minimum of the Taylor series\n",
    "approximation of $\\chi^2(a,b)$. This method is only good if the second\n",
    "order Taylor series provides a good approximation of $\\chi^2(a,b)$. That\n",
    "is why parabolic extrapolation only works well very near the minimum in\n",
    "$\\chi^2(a,b)$.\n",
    "\n",
    "Before illustrating the Levenberg-Marquardt method, we make one\n",
    "important cautionary remark: the Levenberg-Marquardt method can fail if\n",
    "the initial guesses of the fitting parameters are too far away from the\n",
    "desired solution. This problem becomes more serious the greater the\n",
    "number of fitting parameters. Thus it is important to provide reasonable\n",
    "initial guesses for the fitting parameters. Usually, this is not a\n",
    "problem, as it is clear from the physical situation of a particular\n",
    "experiment what reasonable values of the fitting parameters are. But\n",
    "beware!\n",
    "\n",
    "single: SciPy; nonlinear curve fitting\n",
    "\n",
    "The `scipy.optimize` module provides routines that implement the\n",
    "Levenberg-Marquardt non-linear fitting method. One is called\n",
    "`scipy.optimize.leastsq`. A somewhat more user-friendly version of the\n",
    "same method is accessed through another routine in the same\n",
    "`scipy.optimize` module: it's called `scipy.optimize.curve_fit` and it\n",
    "is the one we demonstrate here. The function call is :\n",
    "\n",
    "    import scipy.optimize\n",
    "    [... insert code here ...]\n",
    "    scipy.optimize.curve_fit(f, xdata, ydata, p0=None, sigma=None, \n",
    "                             **kwargs)\n",
    "\n",
    "The arguments of `curve_fit` are\n",
    "\n",
    "> -   `f(xdata, a, b, ...)`: is the fitting function where `xdata` is\n",
    ">     the data for the independent variable and `a, b, ...` are the\n",
    ">     fitting parameters, however many there are, listed as separate\n",
    ">     arguments. Obviously, `f(xdata, a, b, ...)` should return the $y$\n",
    ">     value of the fitting function.\n",
    "> -   `xdata`: is the array containing the $x$ data.\n",
    "> -   `ydata`: is the array containing the $y$ data.\n",
    "> -   `p0`: is a tuple containing the initial guesses for the fitting\n",
    ">     parameters. The guesses for the fitting parameters are set equal\n",
    ">     to 1 if they are left unspecified. It is almost always a good idea\n",
    ">     to specify the initial guesses for the fitting parameters.\n",
    "> -   `sigma`: is the array containing the uncertainties in the $y$\n",
    ">     data.\n",
    "> -   `**kwargs`: are keyword arguments that can be passed to the\n",
    ">     fitting routine `scipy.optimize.leastsq` that `curve_fit` calls.\n",
    ">     These are usually left unspecified.\n",
    "\n",
    "We demonstrate the use of `curve_fit` to fit the data plotted in the\n",
    "figure below:\n",
    "\n",
    "<figure>\n",
    "<img src=\"attachment:Spectrum.png\" class=\"align-center\" alt=\"\" />\n",
    "</figure>\n",
    "\n",
    "We model the data with the fitting function that consists of a quadratic\n",
    "polynomial background with a Gaussian peak:\n",
    "\n",
    "$$A(f) = a + bf + cf^2 + P e^{-\\frac{1}{2}[(f-f_p)/f_w]^2} .$$\n",
    "\n",
    "Lines 7 and 8 define the fitting functions. Note that the independent\n",
    "variable `f` is the first argument, which is followed by the six fitting\n",
    "parameters $a$, $b$, $c$, $P$, $f_p$, and $f_w$.\n",
    "\n",
    "To fit the data with $A(f)$, we need good estimates of the fitting\n",
    "parameters. Setting $f=0$, we see that $a \\approx 60$. An estimate of\n",
    "the slope of the baseline gives $b \\approx -60/20=-3$. The curvature in\n",
    "the baseline is small so we take $c \\approx 0$. The amplitude of the\n",
    "peak above the baseline is $P \\approx 110-30=80$. The peak is centered\n",
    "at $f_p \\approx 11$, while width of peak is about $f_w \\approx 2$. We\n",
    "use these estimates to set the initial guesses of the fitting parameters\n",
    "in lines 14 and 15 in the code below.\n",
    "\n",
    "single: list comprehension\n",
    "\n",
    "The function that performs the Levenverg-Marquardt algorithm, <span\n",
    "class=\"title-ref\">scipy.optimize.curve\\_fit</span>, is called in lines\n",
    "19-20 with the output set equal to the one and two-dimensional arrays\n",
    "`nlfit` and `nlpcov`, respectively. The array `nlfit`, which gives the\n",
    "optimal values of the fitting parameters, is unpacked in line 23. The\n",
    "square root of the diagonal of the two-dimensional array `nlpcov`, which\n",
    "gives the estimates of the uncertainties in the fitting parameters, is\n",
    "unpacked in lines 26-27 using a list comprehension.\n",
    "\n",
    "The rest of the code plots the data, the fitting function using the\n",
    "optimal values of the fitting parameters found by\n",
    "`scipy.optimize.curve_fit`, and the values of the fitting parameters and\n",
    "their uncertainties.\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec  # for unequal plot boxes\n",
    "import scipy.optimize\n",
    "\n",
    "# define fitting function\n",
    "def GaussPolyBase(f, a, b, c, P, fp, fw):\n",
    "    return a + b*f + c*f*f + P*np.exp(-0.5*((f-fp)/fw)**2)\n",
    "\n",
    "# read in spectrum from data file\n",
    "# f=frequency, s=signal, ds=s uncertainty\n",
    "f, s, ds = np.loadtxt(\"Spectrum.txt\", skiprows=4, unpack=True)\n",
    "\n",
    "# initial guesses for fitting parameters\n",
    "a0, b0, c0 = 60., -3., 0.\n",
    "P0, fp0, fw0 = 80., 11., 2.\n",
    "\n",
    "# fit data using SciPy's Levenberg-Marquart method\n",
    "nlfit, nlpcov = scipy.optimize.curve_fit(GaussPolyBase, \n",
    "                f, s, p0=[a0, b0, c0, P0, fp0, fw0], sigma=ds)\n",
    "\n",
    "# unpack fitting parameters\n",
    "a, b, c, P, fp, fw = nlfit\n",
    "# unpack uncertainties in fitting parameters from diagonal\n",
    "# of covariance matrix\n",
    "da, db, dc, dP, dfp, dfw = \\\n",
    "          [np.sqrt(nlpcov[j,j]) for j in range(nlfit.size)]\n",
    "\n",
    "# create fitting function from fitted parameters\n",
    "f_fit = np.linspace(0.0, 25., 128)\n",
    "s_fit = GaussPolyBase(f_fit, a, b, c, P, fp, fw)\n",
    "\n",
    "# Calculate residuals and reduced chi squared\n",
    "resids = s - GaussPolyBase(f, a, b, c, P, fp, fw)\n",
    "redchisqr = ((resids/ds)**2).sum()/float(f.size-6)\n",
    "\n",
    "# Create figure window to plot data\n",
    "fig = plt.figure(1, figsize=(8,8))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[6, 2])\n",
    "\n",
    "# Top plot: data and fit\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.plot(f_fit, s_fit)\n",
    "ax1.errorbar(f, s, yerr=ds, fmt='or', ecolor='black')\n",
    "ax1.set_xlabel('frequency (THz)')\n",
    "ax1.set_ylabel('absorption (arb units)')\n",
    "ax1.text(0.7, 0.95, 'a = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(a, da), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.90, 'b = {0:0.2f}$\\pm${1:0.2f}'\n",
    "         .format(b, db), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.85, 'c = {0:0.2f}$\\pm${1:0.2f}'\n",
    "         .format(c, dc), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.80, 'P = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(P, dP), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.75, 'fp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(fp, dfp), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.70, 'fw = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(fw, dfw), transform = ax1.transAxes)\n",
    "ax1.text(0.7, 0.60, '$\\chi_r^2$ = {0:0.2f}'\n",
    "         .format(redchisqr),transform = ax1.transAxes)\n",
    "ax1.set_title('$s(f) = a+bf+cf^2+P\\,e^{-(f-f_p)^2/2f_w^2}$')\n",
    "\n",
    "# Bottom plot: residuals\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax2.errorbar(f, resids, yerr = ds, ecolor=\"black\", fmt=\"ro\")\n",
    "ax2.axhline(color=\"gray\", zorder=-1)\n",
    "ax2.set_xlabel('frequency (THz)')\n",
    "ax2.set_ylabel('residuals')\n",
    "ax2.set_ylim(-20, 20)\n",
    "ax2.set_yticks((-20, 0, 20))\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The above code also plots the difference between the data and fit, known\n",
    "as the *residuals* in the subplot below the plot of the data and fit.\n",
    "Plotting the residuals in this way gives a graphical representation of\n",
    "the goodness of the fit. To the extent that the residuals vary randomly\n",
    "about zero and do not show any overall upward or downward curvature, or\n",
    "any long wavelength oscillations, the fit would seem to be a good fit.\n",
    "\n",
    "<figure>\n",
    "<img src=\"attachment:FitSpectrum.png\" class=\"align-center\" alt=\"\" /><figcaption>Fit to Gaussian with quadratic polynomial background.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Finally, we note that we have used the MatPlotLib package `gridspec` to\n",
    "create the two subplots with different heights. The `gridspec` are made\n",
    "in lines 3 (where the package is imported), 36 (where 2 rows and 1\n",
    "column are specified with relative heights of 6 to 2), 39 (where the\n",
    "first `gs[0]` height is specified), and 54 (where the second `gs[1]`\n",
    "height is specified). More details about the `gridspec` package can be\n",
    "found at the MatPlotLib web site.\n",
    "\n",
    "Exercises\n",
    "---------\n",
    "\n",
    "1.  When a voltage source is connected across a resistor and inductor in\n",
    "    series, the voltage across the inductor $V_i(t)$ is predicted to\n",
    "    obey the equation\n",
    "\n",
    "    $$V(t) = V_0 e^{-\\Gamma t}$$\n",
    "\n",
    "    where $t$ is the time and the decay rate $\\Gamma=R/L$ is the ratio\n",
    "    of the resistance $R$ to the inductance $L$ of the circuit. In this\n",
    "    problem, you are to write a Python routine that fits the above\n",
    "    equation to the data below for the voltage measured across an\n",
    "    inductor after it is connected in series with a resistor to a\n",
    "    voltage source. Following the example in the text, linearize the\n",
    "    `eq:inductorDecay` and use a linear fitting routine, either the one\n",
    "    you wrote from the previous chapter or one from NumPy or SciPy.\n",
    "\n",
    "    1.  Find the best values of $\\Gamma$ and $V_0$ and the uncertainties\n",
    "        in their values $\\sigma_\\Gamma$ and $\\sigma_{V_0}$.\n",
    "\n",
    "    2.  Find the value of $\\chi_r^2$ for your fit. Does it make sense?\n",
    "\n",
    "    3.  Make a semi-log plot of the data using symbols with error bars\n",
    "        (no line) and of the fit (line only). The fit should appear as a\n",
    "        straight line that goes through the data points.\n",
    "\n",
    "    4.  If the resistor has a value of 10.0 $\\mathrm{k}\\Omega$, what is\n",
    "        the value of the inductance and its uncertainty according to\n",
    "        your fit, assuming that the error in the resistance is\n",
    "        negligibly small.\n",
    "\n",
    "            Data for decay of voltage across an inductor\n",
    "            in an RL circuit\n",
    "            Date: 24-Oct-2012\n",
    "            Data taken by D. M. Blantogg and T. P. Chaitor\n",
    "\n",
    "            time (ns)   voltage (volts)  uncertainty (volts)\n",
    "                0.0        5.08e+00        1.12e-01\n",
    "               32.8        3.29e+00        9.04e-02\n",
    "               65.6        2.23e+00        7.43e-02\n",
    "               98.4        1.48e+00        6.05e-02\n",
    "              131.2        1.11e+00        5.25e-02\n",
    "              164.0        6.44e-01        4.00e-02\n",
    "              196.8        4.76e-01        3.43e-02\n",
    "              229.6        2.73e-01        2.60e-02\n",
    "              262.4        1.88e-01        2.16e-02\n",
    "              295.2        1.41e-01        1.87e-02\n",
    "              328.0        9.42e-02        1.53e-02\n",
    "              360.8        7.68e-02        1.38e-02\n",
    "              393.6        3.22e-02        8.94e-03\n",
    "              426.4        3.22e-02        8.94e-03\n",
    "              459.2        1.98e-02        7.01e-03\n",
    "              492.0        1.98e-02        7.01e-03\n",
    "\n",
    "2.  Small nanoparticles of soot suspended in water start to aggregate\n",
    "    when salt is added. The average radius $r$ of the aggregates is\n",
    "    predicted to grow as a power law in time $t$ according to the\n",
    "    equation $r = r_0t^n$. Taking the logarithm of this equation gives\n",
    "    $\\ln r = n\\ln t + \\ln r_0$. Thus the data should fall on a straight\n",
    "    line if $\\ln r$ is plotted *vs* $\\ln t$.\n",
    "\n",
    "    1.  Plot the data below on a graph of $\\ln r$ *vs* $\\ln t$ to see if\n",
    "        the data fall approximately on a straight line.\n",
    "\n",
    "            Size of growing aggregate\n",
    "            Date: 19-Nov-2013\n",
    "            Data taken by M. D. Gryart and M. L. Waites\n",
    "            time (m)   size (nm)    unc (nm)\n",
    "              0.12        115         10\n",
    "              0.18        130         12\n",
    "              0.42        202         14\n",
    "              0.90        335         18\n",
    "              2.10        510         20\n",
    "              6.00        890         30\n",
    "             18.00       1700         40\n",
    "             42.00       2600         50\n",
    "\n",
    "    2.  Defining $y = \\ln r$ and $x = \\ln t$, use the linear fitting\n",
    "        routine you wrote for the previous problem to fit the data and\n",
    "        find the optimal values for the slope and $y$ intercept, as well\n",
    "        as their uncertainties. Use these fitted values to find the\n",
    "        optimal values of the the amplitude $r_0$ and the power $n$ in\n",
    "        the fitting function $r = r_0t^n$. What are the fitted values of\n",
    "        $r_0$ and $n$? What is the value of $\\chi_r^2$? Does a power law\n",
    "        provide an adequate model for the data?\n",
    "\n",
    "3.  In this problem you explore using a non-linear least square fitting\n",
    "    routine to fit the data shown in the figure below. The data,\n",
    "    including the uncertainties in the $y$ values, are provided in the\n",
    "    table below. Your task is to fit the function\n",
    "\n",
    "    $$d(t) = A (1+B\\,\\cos\\omega t) e^{-t^2/2\\tau^2} + C$$\n",
    "\n",
    "    to the data, where the fitting parameters are $A$, $B$, $C$,\n",
    "    $\\omega$, and $\\tau$.\n",
    "\n",
    "    <figure>\n",
    "    <img src=\"attachment:DataOscDecay.png\" class=\"align-center\" alt=\"\" />\n",
    "    </figure>\n",
    "\n",
    "    1.  Write a Python program that (*i*) reads the data in from a data\n",
    "        file, (*ii*) defines a function\n",
    "        `oscDecay(t, A, B, C, tau, omega)` for the function $d(t)$\n",
    "        above, and (*iii*) produces a plot of the data and the function\n",
    "        $d(t)$. Choose the fitting parameters `A`, `B`, `C`, `tau`, and\n",
    "        `omega` to produce an approximate fit \"by eye\" to the data. You\n",
    "        should be able estimate reasonable values for these parameters\n",
    "        just by looking at the data and thinking about the behavior of\n",
    "        $d(t)$. For example, $d(0)=A(1+B)+C$ while $d(\\infty)=C$. What\n",
    "        parameter in $d(t)$ controls the period of the peaks observed in\n",
    "        the data? Use that information to estimate the value of that\n",
    "        parameter.\n",
    "\n",
    "    2.  Following the example in section `sec:nonlinfit`, write a\n",
    "        program using the SciPy function `scipy.optimize.curve_fit` to\n",
    "        fit Eq. `eq:OscDecay` to the data and thus find the optimal\n",
    "        values of the fitting parameters $A$, $B$, $C$, $\\omega$, and\n",
    "        $\\tau$. Your program should plot the data along with the fitting\n",
    "        function using the optimal values of the fitting parameters.\n",
    "        Write a function to calculate the reduced $\\chi^2$. Print out\n",
    "        the value of the reduced $\\chi^2$ on your plot along with the\n",
    "        optimal values of the fitting parameters. You can use the\n",
    "        results from part (a) to estimate good starting values of the\n",
    "        fitting parameters\n",
    "\n",
    "    3.  Once you have found the optimal fitting parameters, run your\n",
    "        fitting program again using for starting values the optimal\n",
    "        values of the fitting parameters $A$, $B$, $C$, and $\\tau$, but\n",
    "        set the starting value of $\\omega$ to be 3 times the optimal\n",
    "        value. You should find that the program converges to a different\n",
    "        set of fitting parameters than the ones you found in part (b).\n",
    "        Using the program you wrote for part (b) make a plot of the data\n",
    "        and the fit like the one you did for part (a). The fit should be\n",
    "        noticeably worse. What is the value of the reduced $\\chi^2$ for\n",
    "        this fit; it should be much larger than the one you found for\n",
    "        part (c). The program has found a local minimum in\n",
    "        $\\chi^2$---one that is obviously is not the best fit!\n",
    "\n",
    "    4.  Setting the fitting parameters $A$, $B$, $C$, and $\\tau$ to the\n",
    "        optimal values you found in part (b), plot $\\chi_r^2$ as a\n",
    "        function of $\\omega$ for $\\omega$ spanning the range from 0.05\n",
    "        to 3.95. You should observe several local minima for different\n",
    "        values of $\\chi_r^2$; the global minimum in $\\chi_r^2$ should\n",
    "        occur for the optimal value of $\\omega$ you found in part (b).\n",
    "\n",
    "            Data for absorption spectrum\n",
    "            Date: 21-Nov-2012\n",
    "            Data taken by P. Dubson and M. Sparks\n",
    "            time (ms)  signal  uncertainty\n",
    "              0.2      41.1       0.9 \n",
    "              1.4      37.2       0.9 \n",
    "              2.7      28.3       0.9 \n",
    "              3.9      24.8       1.1 \n",
    "              5.1      27.8       0.8 \n",
    "              6.4      34.5       0.7 \n",
    "              7.6      39.0       0.9 \n",
    "              8.8      37.7       0.8 \n",
    "             10.1      29.8       0.9 \n",
    "             11.3      22.2       0.7 \n",
    "             12.5      22.3       0.6 \n",
    "             13.8      26.7       1.1 \n",
    "             15.0      30.4       0.7 \n",
    "             16.2      32.6       0.8 \n",
    "             17.5      28.9       0.8 \n",
    "             18.7      22.9       1.3 \n",
    "             19.9      21.7       0.9 \n",
    "             21.1      22.1       1.0 \n",
    "             22.4      22.3       1.0 \n",
    "             23.6      26.3       1.0 \n",
    "             24.8      26.2       0.8 \n",
    "             26.1      21.4       0.9 \n",
    "             27.3      20.0       1.0 \n",
    "             28.5      20.1       1.2 \n",
    "             29.8      21.2       0.5 \n",
    "             31.0      22.0       0.9 \n",
    "             32.2      21.6       0.7 \n",
    "             33.5      21.0       0.7 \n",
    "             34.7      19.7       0.9 \n",
    "             35.9      17.9       0.9 \n",
    "             37.2      18.1       0.8 \n",
    "             38.4      18.9       1.1 "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-language_info"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224.097px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}